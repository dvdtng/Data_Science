{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPMG Data Kontest - Detection of fake news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import contractions\n",
    "import inflect\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import argparse\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import six\n",
    "from abc import ABCMeta\n",
    "from scipy import sparse\n",
    "from scipy.sparse import issparse\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils import check_X_y, check_array\n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "from sklearn.preprocessing import normalize, binarize, LabelBinarizer\n",
    "\n",
    "import xgboost as xg\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier,AdaBoostClassifier)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Train.csv\", dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['content'].duplicated() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VIDEO: The World Reacts to the Paris Attacks\\r...</td>\n",
       "      <td>VIDEO: The World Reacts to the Paris Attacks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Philippine finance secretary, Jose Camacho...</td>\n",
       "      <td>Philippines Denies It Is Boycotting UBS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Now 18M Users Strong, Edmodo Makes Its First A...</td>\n",
       "      <td>Now 18M Users Strong, Edmodo Makes Its First A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moral Hazard: The Federal Reserve And Financia...</td>\n",
       "      <td>Moral Hazard: The Federal Reserve And Financia...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Two Jewish Teens Beaten And Robbed Leaving Syn...</td>\n",
       "      <td>Anti-Semitism – Liberty News</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A prosecutor is suing the judge overseeing the...</td>\n",
       "      <td>National Briefing: South: Georgia: Prosecutor ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>An expert at Sotheby's said that Mr. Shearman'...</td>\n",
       "      <td>An Old Master Sold at Auction Raises Doubts; S...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In Piermont, housing prices have risen 8 to 10...</td>\n",
       "      <td>If You're Thinking of Living In/Piermont, N.Y....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FRANKEL-Hon. Marvin E. Yeshiva University and ...</td>\n",
       "      <td>Paid Notice: Deaths  FRANKEL, HON. MARVIN E.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-San Antonio Police Try to Silence Street Prea...</td>\n",
       "      <td>-San Antonio Police Try to Silence Street Prea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Correction Appended\\r\\r\\r\\n\\r\\r\\r\\nA listing o...</td>\n",
       "      <td>Corrections</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Eva Moskowitz, the charter-school leader who h...</td>\n",
       "      <td>N.Y. Charter-School Leader Eva Moskowitz Says ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ms. Gazale, Ms. Zenadeen and their director, M...</td>\n",
       "      <td>A Lebanese Parody? Don't Worry. You'll Get It.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Written by Lalmani Verma | Lucknow | Published...</td>\n",
       "      <td>Uttar Pradesh Polls: At SP rally, calls for Mu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Important Info From Tugboat Harry\\r\\r\\r\\n\\r\\r\\...</td>\n",
       "      <td>Important Info From Tugboat Harry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(Before It's News)\\r\\r\\r\\n\\r\\r\\r\\nBy Gary P Ja...</td>\n",
       "      <td>Chick-fil-A VP Don Perry Dies Suddenly, Libera...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fight to restrict second home ownership in pic...</td>\n",
       "      <td>One in four buy-to-let investors sell up due t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"It's nice to get off to a good start for the ...</td>\n",
       "      <td>Johnson Continues To Set Fast Cup Pace</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BOISE, Idaho -- Barack who? Representative Wal...</td>\n",
       "      <td>Six Districts, Two Sides, One Weekend: The Sel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>To the Editor:\\r\\r\\r\\n\\r\\r\\r\\nRe “Another Stor...</td>\n",
       "      <td>Enough Already! Bury Power Lines; Bitter Disag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  \\\n",
       "0   VIDEO: The World Reacts to the Paris Attacks\\r...   \n",
       "1   The Philippine finance secretary, Jose Camacho...   \n",
       "2   Now 18M Users Strong, Edmodo Makes Its First A...   \n",
       "3   Moral Hazard: The Federal Reserve And Financia...   \n",
       "4   Two Jewish Teens Beaten And Robbed Leaving Syn...   \n",
       "5   A prosecutor is suing the judge overseeing the...   \n",
       "6   An expert at Sotheby's said that Mr. Shearman'...   \n",
       "7   In Piermont, housing prices have risen 8 to 10...   \n",
       "8   FRANKEL-Hon. Marvin E. Yeshiva University and ...   \n",
       "9   -San Antonio Police Try to Silence Street Prea...   \n",
       "10  Correction Appended\\r\\r\\r\\n\\r\\r\\r\\nA listing o...   \n",
       "11  Eva Moskowitz, the charter-school leader who h...   \n",
       "12  Ms. Gazale, Ms. Zenadeen and their director, M...   \n",
       "13  Written by Lalmani Verma | Lucknow | Published...   \n",
       "14  Important Info From Tugboat Harry\\r\\r\\r\\n\\r\\r\\...   \n",
       "15  (Before It's News)\\r\\r\\r\\n\\r\\r\\r\\nBy Gary P Ja...   \n",
       "16  Fight to restrict second home ownership in pic...   \n",
       "17  \"It's nice to get off to a good start for the ...   \n",
       "18  BOISE, Idaho -- Barack who? Representative Wal...   \n",
       "19  To the Editor:\\r\\r\\r\\n\\r\\r\\r\\nRe “Another Stor...   \n",
       "\n",
       "                                                title fake  \n",
       "0        VIDEO: The World Reacts to the Paris Attacks    1  \n",
       "1             Philippines Denies It Is Boycotting UBS    0  \n",
       "2   Now 18M Users Strong, Edmodo Makes Its First A...    1  \n",
       "3   Moral Hazard: The Federal Reserve And Financia...    1  \n",
       "4                        Anti-Semitism – Liberty News    1  \n",
       "5   National Briefing: South: Georgia: Prosecutor ...    0  \n",
       "6   An Old Master Sold at Auction Raises Doubts; S...    0  \n",
       "7   If You're Thinking of Living In/Piermont, N.Y....    0  \n",
       "8        Paid Notice: Deaths  FRANKEL, HON. MARVIN E.    0  \n",
       "9   -San Antonio Police Try to Silence Street Prea...    1  \n",
       "10                                        Corrections    0  \n",
       "11  N.Y. Charter-School Leader Eva Moskowitz Says ...    0  \n",
       "12     A Lebanese Parody? Don't Worry. You'll Get It.    0  \n",
       "13  Uttar Pradesh Polls: At SP rally, calls for Mu...    0  \n",
       "14                  Important Info From Tugboat Harry    1  \n",
       "15  Chick-fil-A VP Don Perry Dies Suddenly, Libera...    1  \n",
       "16  One in four buy-to-let investors sell up due t...    0  \n",
       "17             Johnson Continues To Set Fast Cup Pace    0  \n",
       "18  Six Districts, Two Sides, One Weekend: The Sel...    0  \n",
       "19  Enough Already! Bury Power Lines; Bitter Disag...    0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Moral Hazard: The Federal Reserve And Financial Markets – Paul-Martin Foss\\r\\r\\r\\n\\r\\r\\r\\n(Before It's News)\\r\\r\\r\\n\\r\\r\\r\\nTND Guest Contributor: Paul-Martin Foss |\\r\\r\\r\\n\\r\\r\\r\\nOne of the problems with central banks acting as a lender of last resort is that of moral hazard. With the cost of bailouts spread out across society and benefits concentrated to a few large firms, the temptation to engage in excessively risky behavior is ever-present. Financial firms have become so used to getting their way from the government that they assume the Fed will bail them out of every difficult spot that comes along. The Federal Reserve’s monetary policy of the past eight years has been one huge bailout, funneling trillions of dollars of easy money to Wall Street, boosting stock prices, and creating bubbles throughout the economy. This loose monetary policy has led to such malinvestment that the economy will definitely fall into a recession or depression once the Fed takes away the punch bowl. Stock markets realize that the economy’s fundamentals are unsound, that firms are reliant on cheap central bank money for their continued performance, so the specter of Federal Reserve rate hikes and monetary policy normalization is leading to panic.\\r\\r\\r\\n\\r\\r\\r\\nIn the days before the creation of the Federal Reserve System, banks still had to deal with the problem of a lender of last resort. If a bank was solvent (its assets were greater than its liabilities) but was temporarily illiquid (didn’t have cash on hand or assets that could be readily liquidated to get cash) what would happen? What if this temporary liquidity problem were only for one day and the bank had payments coming due the next day that would it enable to pay back what it owed? It didn’t make sense to force a bank into bankruptcy just because it was temporarily unable to pay its transfers to other banks, so banks formedclearinghouse associations to remedy those situations. Banks would pay a certain portion of their reserves to the clearinghouse, normally housed at a large bank, to be drawn on in case of a temporary liquidity problem. If a bank found itself at the end of the day unable to pay checks drawn on its accounts, it could borrow money overnight from the clearinghouse, paying it back the next day with interest once it had money again.\\r\\r\\r\\n\\r\\r\\r\\nNaturally these clearinghouses, like any form of insurance, could lead to moral hazard. Because the risks were being being dispersed over the membership of the clearinghouse, an individual bank might be tempted to play a little fast and loose, dipping into clearinghouse funds on a regular basis in order to balance its accounts. The solution to this was to charge banks rates that were high enough to discourage regular resorting to the clearinghouse, encouraging banks to use them only as a last resort. But banks don’t like paying market interest rates, so they lobby for government-sponsored or controlled central banks. A clearinghouse can only lend if its members agree to set aside reserves, and it can’t lend any more than those reserves. Central banks have no such limitations as the money they create and lend to banks literally comes from nowhere. It can lend to its heart’s content and at rates far lower than clearinghouses, with their market-based rates, would charge.\\r\\r\\r\\n\\r\\r\\r\\nThis ability to act as a unlimited lender of last resort has been used often, but never before to the extent that it was during the financial crisis. While the past century saw unprecedented interventions by central banks, recent central bank actions such as quantitative easing and negative interest rates would make the creators of the Federal Reserve System blanch with fright. The fact that markets panic at the thought of the Fed shutting off its pipeline of easy money should give warning that the US economy is fundamentally unsound. Moral hazard is endemic to Wall Street today and the expectation of bailouts continues to pervade the thinking of financial markets. Too many people when talking about “Too Big to Fail” focus on the “Too Big” and not the “To Fail.” Despite rhetoric that “Too Big To Fail” is over, when the rubber meets the road the Fed will undoubtedly step in to prevent a large bank from failing and taking down the financial system. The only way to end “Too Big To Fail” is to end the institution that incentivizes excessive risk-taking, enables banks to grow impossibly large, and keeps those big banks from failing: the Federal Reserve System.\\r\\r\\r\\n\\r\\r\\r\\nImage: Rafael Matsunaga\\r\\r\\r\\n\\r\\r\\r\\n# # # #\\r\\r\\r\\n\\r\\r\\r\\nAbout Paul-Martin Foss:\\r\\r\\r\\n\\r\\r\\r\\nPaul-Martin Foss is the founder, President, and Executive Director of the Carl Menger Center for the Study of Money and Banking, an Arlington, VA-based think tank dedicated to educating the American people on the importance of sound money and sound banking.\\r\\r\\r\\n\\r\\r\\r\\nPrior to founding the Menger Center, Mr. Foss worked in the U.S. House of Representatives for seven years, including six years as Congressman Ron Paul’s legislative assistant for monetary policy and financial services, and one year as Deputy Legislative Director for Congressman Thomas Massie.\\r\\r\\r\\n\\r\\r\\r\\nAs Congressman Paul’s legislative assistant, he assisted the Congressman in his duties as Chairman of the Subcommittee on Domestic Monetary Policy by helping to develop hearing topics, agendas, and briefing Congressmen and their staffs on monetary policy topics. Mr. Foss also was responsible for the management of Dr. Paul’s monetary policy and financial services legislation, including the “Audit the Fed” and “End the Fed” bills, and was co-editor of Ron Paul’s Monetary Policy Anthology, a multi-thousand page compilation of hearing transcripts, lecture transcripts, and other documents related to Dr. Paul’s chairmanship.\\r\\r\\r\\n\\r\\r\\r\\nMr. Foss received his Bachelor’s degree from The University of the South (Sewanee), and Master’s degrees from the London School of Economics and Georgetown University’s Edmund A. Walsh School of Foreign Service.\\r\\r\\r\\n\\r\\r\\r\\nThis article appeared on the Carl Menger Center for the Study of Money and Banking and is reprinted with permission, “Creative Commons 4.0.”\\r\\r\\r\\n\\r\\r\\r\\nSource: http://thenewsdoctors.com/moral-hazard-the-federal-reserve-and-financial-markets-paul-martin-fos/\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eg of an article\n",
    "train.content[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "def replace_contractions(text):\n",
    "    \"\"\"Replace contractions in string of text\"\"\"\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "def stem_words(text):\n",
    "    return LancasterStemmer.stem(text)\n",
    "\n",
    "def lemmatize_verbs(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return lemmatizer.lemmatize(text, pos='v')\n",
    "\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = contractions.fix(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the  0 th item\n",
      "Here is the  5000 th item\n",
      "Here is the  10000 th item\n",
      "Here is the  15000 th item\n",
      "Here is the  20000 th item\n",
      "Here is the  25000 th item\n",
      "Here is the  30000 th item\n",
      "Here is the  35000 th item\n",
      "Here is the  40000 th item\n",
      "Here is the  45000 th item\n",
      "Here is the  50000 th item\n",
      "Here is the  55000 th item\n",
      "Here is the  60000 th item\n",
      "Here is the  65000 th item\n"
     ]
    }
   ],
   "source": [
    "# Applying denoise_text function on the content column\n",
    "for idx, item in enumerate(train.content):\n",
    "    train.iloc[idx,0] = denoise_text(item)\n",
    "    if idx%5000 == 0:\n",
    "        print('Here is the ',idx,'th item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbc = len(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainheadlines = []\n",
    "for j in range(0,len(train.index)):\n",
    "    trainheadlines.append(' '.join(str(x) for x in train.iloc[j,:nbc-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 7513439)\n"
     ]
    }
   ],
   "source": [
    "# advancedtrain training examples : CountVectorizer performed better than TF-IDF in my usecase\n",
    "# To try if time : Glove, Bert, Gensim\n",
    "advancedvectorizer = CountVectorizer(ngram_range=(1,3), strip_accents ='ascii', decode_error='ignore', lowercase=True)\n",
    "advancedtrain = advancedvectorizer.fit_transform(trainheadlines)\n",
    "print(advancedtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 7513439)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advancedtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets - output for my training examples\n",
    "targets = train['fake'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(advancedtrain, targets, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did not performed a cross validation in this notebook due to the short time left for submitting results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Logistic regression :  logit with C=0.5 and lasso penality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "advancedmodel = LogisticRegression(penalty='l1', C=0.5)\n",
    "advancedmodel = advancedmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logit classifier on training set: 0.996629\n",
      "Accuracy of Logit classifier on test set: 0.968914\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logit classifier on training set: {:.6f}'.format(advancedmodel.score(X_train, y_train)))\n",
    "print('Accuracy of Logit classifier on test set: {:.6f}'.format(advancedmodel.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. NBSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBSVM(six.with_metaclass(ABCMeta, BaseEstimator, ClassifierMixin)):\n",
    "\n",
    "    def __init__(self, alpha=1.0, C=1.0, max_iter=10000):\n",
    "        self.alpha = alpha\n",
    "        self.max_iter = max_iter\n",
    "        self.C = C\n",
    "        self.svm_ = [] # fuggly\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y, 'csr')\n",
    "        _, n_features = X.shape\n",
    "\n",
    "        labelbin = LabelBinarizer()\n",
    "        Y = labelbin.fit_transform(y)\n",
    "        self.classes_ = labelbin.classes_\n",
    "        if Y.shape[1] == 1:\n",
    "            Y = np.concatenate((1 - Y, Y), axis=1)\n",
    "\n",
    "        # LabelBinarizer().fit_transform() returns arrays with dtype=np.int64.\n",
    "        # so we don't have to cast X to floating point\n",
    "        Y = Y.astype(np.float64)\n",
    "\n",
    "        # Count raw events from data\n",
    "        n_effective_classes = Y.shape[1]\n",
    "        self.class_count_ = np.zeros(n_effective_classes, dtype=np.float64)\n",
    "        self.ratios_ = np.full((n_effective_classes, n_features), self.alpha,\n",
    "                                 dtype=np.float64)\n",
    "        self._compute_ratios(X, Y)\n",
    "\n",
    "        # flugglyness\n",
    "        for i in range(n_effective_classes):\n",
    "            X_i = X.multiply(self.ratios_[i])\n",
    "            svm = LinearSVC(C=self.C, max_iter=self.max_iter)\n",
    "            Y_i = Y[:,i]\n",
    "            svm.fit(X_i, Y_i)\n",
    "            self.svm_.append(svm) \n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        n_effective_classes = self.class_count_.shape[0]\n",
    "        n_examples = X.shape[0]\n",
    "\n",
    "        D = np.zeros((n_effective_classes, n_examples))\n",
    "\n",
    "        for i in range(n_effective_classes):\n",
    "            X_i = X.multiply(self.ratios_[i])\n",
    "            D[i] = self.svm_[i].decision_function(X_i)\n",
    "        \n",
    "        return self.classes_[np.argmax(D, axis=0)]\n",
    "        \n",
    "    def _compute_ratios(self, X, Y):\n",
    "        \"\"\"Count feature occurrences and compute ratios.\"\"\"\n",
    "        if np.any((X.data if issparse(X) else X) < 0):\n",
    "            raise ValueError(\"Input X must be non-negative\")\n",
    "\n",
    "        self.ratios_ += safe_sparse_dot(Y.T, X)  # ratio + feature_occurrance_c\n",
    "        normalize(self.ratios_, norm='l1', axis=1, copy=False)\n",
    "        row_calc = lambda r: np.log(np.divide(r, (1 - r)))\n",
    "        self.ratios_ = np.apply_along_axis(row_calc, axis=1, arr=self.ratios_)\n",
    "        check_array(self.ratios_)\n",
    "        self.ratios_ = sparse.csr_matrix(self.ratios_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logit classifier on training set: 1.000000\n",
      "Accuracy of Logit classifier on test set: 0.964686\n"
     ]
    }
   ],
   "source": [
    "advancedmodel3 = NBSVM()\n",
    "advancedmodel3 = advancedmodel3.fit(X_train, y_train)\n",
    "\n",
    "# countvectorizer avec balanced # LOGIT avec tout le pre-processing\n",
    "print('Accuracy of Logit classifier on training set: {:.6f}'.format(advancedmodel3.score(X_train, y_train)))\n",
    "print('Accuracy of Logit classifier on test set: {:.6f}'.format(advancedmodel3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Linear SVC with C = 0.05, squared hinge loss, lasso penality and primal problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logit classifier on training set: 0.985867\n",
      "Accuracy of Logit classifier on test set: 0.967371\n"
     ]
    }
   ],
   "source": [
    "advancedmodel = LinearSVC(C=0.05, loss=\"squared_hinge\", penalty='l1', dual=False)\n",
    "advancedmodel = advancedmodel.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of Logit classifier on training set: {:.6f}'.format(advancedmodel.score(X_train, y_train)))\n",
    "print('Accuracy of Logit classifier on test set: {:.6f}'.format(advancedmodel.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing format\n",
    "X_train2 = X_train.astype('float32')\n",
    "X_test2 = X_test.astype('float32')   \n",
    "y_train2 = pd.to_numeric(y_train, errors='coerce')\n",
    "y_test2 =  pd.to_numeric(y_test, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "advancedmodel = LGBMClassifier(application = 'binary',\n",
    "                               objective = 'binary',\n",
    "                               n_jobs = -1, \n",
    "                               verbose = 1,\n",
    "                               max_depth = -1,\n",
    "                               n_estimators = 500,\n",
    "                               num_leaves = 200)\n",
    "advancedmodel = advancedmodel.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LB classifier on training set: 1.000000\n",
      "Accuracy of LB classifier on test set: 0.979314\n"
     ]
    }
   ],
   "source": [
    "# countvectorizer avec balanced\n",
    "print('Accuracy of LB classifier on training set: {:.6f}'.format(advancedmodel.score(X_train2, y_train2)))\n",
    "print('Accuracy of LB classifier on test set: {:.6f}'.format(advancedmodel.score(X_test2, y_test2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to do : embedding + LSTM, Neural networks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
